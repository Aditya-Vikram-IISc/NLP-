{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Text Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r25xOEbllml"
      },
      "source": [
        "#importing the dependencies\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nWNSjeLweSHZ",
        "outputId": "38c9f787-76cf-4dd8-e1fd-8e7b1bd494a1"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52uiHjBEmjWg",
        "outputId": "6bf8a6be-0e6a-4bd6-f1b8-5cb097e77be1"
      },
      "source": [
        "path_to_txt_file = \"/content/shakespeare.txt\"\r\n",
        "\r\n",
        "text = open(path_to_txt_file, \"r\").read()     #reading it characterwise\r\n",
        "print(text[:150])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69VcMwvkndag",
        "outputId": "556620ec-8150-4816-d039-d0bfe25aa751"
      },
      "source": [
        "vocab = sorted(list(set(text)))\r\n",
        "print(vocab)\r\n",
        "print(\"Length of vocab\", len(vocab))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n",
            "Length of vocab 84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZS2gOW3oAoB"
      },
      "source": [
        "### Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdcqIikRndcr",
        "outputId": "e4457d10-4d26-45c3-d84d-291a19645e7a"
      },
      "source": [
        "#Gererating a text to integer encoding dictionary\r\n",
        "\r\n",
        "char_to_ind = {char : ind for (ind, char) in enumerate(vocab)}\r\n",
        "print(char_to_ind)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5, '(': 6, ')': 7, ',': 8, '-': 9, '.': 10, '0': 11, '1': 12, '2': 13, '3': 14, '4': 15, '5': 16, '6': 17, '7': 18, '8': 19, '9': 20, ':': 21, ';': 22, '<': 23, '>': 24, '?': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, '[': 52, ']': 53, '_': 54, '`': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81, '|': 82, '}': 83}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ziZ7cg8qDTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178519c3-431a-4a9d-e5a8-e95451eea358"
      },
      "source": [
        "#Getting an index to character dictionary (or simple arrat as index would give us the character)\r\n",
        "\r\n",
        "ind_to_char = np.array(vocab)\r\n",
        "print(ind_to_char)\r\n",
        "print(\"\\n\")\r\n",
        "print(ind_to_char.dtype)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n' ' ' '!' '\"' '&' \"'\" '(' ')' ',' '-' '.' '0' '1' '2' '3' '4' '5' '6'\n",
            " '7' '8' '9' ':' ';' '<' '>' '?' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J'\n",
            " 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' '[' ']'\n",
            " '_' '`' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p'\n",
            " 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' '|' '}']\n",
            "\n",
            "\n",
            "<U1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6WyO7_eqDVp",
        "outputId": "92d61d2d-a503-4960-d000-e5b140caa7ea"
      },
      "source": [
        "#Now we need to encode our text (corpus) from non-numeric to integers\r\n",
        "print(\"length of the text is :\", len(text))\r\n",
        "\r\n",
        "encoded_text = np.array([char_to_ind[letter] for letter in text])\r\n",
        "print(\"\\n\")\r\n",
        "print(\"Shape of encoded_text is\", encoded_text.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of the text is : 5445609\n",
            "\n",
            "\n",
            "Shape of encoded_text is (5445609,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nYgCYWgf9Jn"
      },
      "source": [
        "###### Understanding the text and encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXhLqTbfndga",
        "outputId": "0261e361-d85f-4753-e7ff-8eea90ee6943"
      },
      "source": [
        "sample = text[:500]\r\n",
        "print(sample)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mHeguNdndii",
        "outputId": "36996a41-0563-4410-f2a9-0caadd53a6ba"
      },
      "source": [
        "encoded_sample = encoded_text[:500]\r\n",
        "encoded_sample"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
              "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
              "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
              "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
              "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
              "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
              "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
              "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
              "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
              "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
              "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
              "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
              "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
              "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
              "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
              "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
              "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
              "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
              "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
              "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
              "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
              "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
              "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
              "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
              "        1, 70, 78, 69,  1, 57, 76])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSneTd86sVL1"
      },
      "source": [
        "### Creating Batches\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbmsf23Bymwe"
      },
      "source": [
        "Overall what we are trying to achieve is to have the model predict the next highest probability character given a historical sequence of characters. Its up to us (the user) to choose how long that historic sequence. Too short a sequence and we don't have enough information (e.g. given the letter \"a\" , what is the next character) , too long a sequence and training will take too long and most likely overfit to sequence characters that are irrelevant to characters farther out. While there is no correct sequence length choice, you should consider the text itself, how long normal phrases are in it, and a reasonable idea of what characters/words are relevant to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxgnUqUwgt2t",
        "outputId": "376d60e4-6768-4e86-a291-40e83e211839"
      },
      "source": [
        "sampled_txt2 = text[:1000]\r\n",
        "print(sampled_txt2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bud buriest thy content,\n",
            "  And tender churl mak'st waste in niggarding:\n",
            "    Pity the world, or else this glutton be,\n",
            "    To eat the world's due, by the grave and thee.\n",
            "\n",
            "\n",
            "                     2\n",
            "  When forty winters shall besiege thy brow,\n",
            "  And dig deep trenches in thy beauty's field,\n",
            "  Thy youth's proud livery so gazed on now,\n",
            "  Will be a tattered weed of small worth held:  \n",
            "  Then being asked, where all thy beauty lies,\n",
            "  Where all the treasure of thy lusty days;\n",
            "  To say within thine own deep su\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKcogLaNg5aX"
      },
      "source": [
        "#One can see that every third line rhymes with the first one approximately. Length of one line ~40. Three lines ~120"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo-QwGTpndkj"
      },
      "source": [
        "seq_len = 120   #Basis text ananlysis that 3 lines of text are sufficient to understand the hiden semantics"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCYtSIDyndm0"
      },
      "source": [
        "total_num_seq = len(text)// (seq_len+1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUw9q2nvndoi",
        "outputId": "02c67691-ed38-4c0d-c842-e5f34444161b"
      },
      "source": [
        "total_num_seq"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP4KKhZuwyWU"
      },
      "source": [
        "#create training sequences\r\n",
        "\r\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P_juh7YmA2x",
        "outputId": "f0c4ebdd-cd9b-46b1-f709-22a23e67d9ab"
      },
      "source": [
        "help(tf.data.Dataset.from_tensor_slices)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function from_tensor_slices in module tensorflow.python.data.ops.dataset_ops:\n",
            "\n",
            "from_tensor_slices(tensors)\n",
            "    Creates a `Dataset` whose elements are slices of the given tensors.\n",
            "    \n",
            "    The given tensors are sliced along their first dimension. This operation\n",
            "    preserves the structure of the input tensors, removing the first dimension\n",
            "    of each tensor and using it as the dataset dimension. All input tensors\n",
            "    must have the same size in their first dimensions.\n",
            "    \n",
            "    >>> # Slicing a 1D tensor produces scalar tensor elements.\n",
            "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
            "    >>> list(dataset.as_numpy_iterator())\n",
            "    [1, 2, 3]\n",
            "    \n",
            "    >>> # Slicing a 2D tensor produces 1D tensor elements.\n",
            "    >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
            "    >>> list(dataset.as_numpy_iterator())\n",
            "    [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n",
            "    \n",
            "    >>> # Slicing a tuple of 1D tensors produces tuple elements containing\n",
            "    >>> # scalar tensors.\n",
            "    >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
            "    >>> list(dataset.as_numpy_iterator())\n",
            "    [(1, 3, 5), (2, 4, 6)]\n",
            "    \n",
            "    >>> # Dictionary structure is also preserved.\n",
            "    >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
            "    >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\n",
            "    ...                                       {'a': 2, 'b': 4}]\n",
            "    True\n",
            "    \n",
            "    >>> # Two tensors can be combined into one Dataset object.\n",
            "    >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
            "    >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
            "    >>> dataset = Dataset.from_tensor_slices((features, labels))\n",
            "    >>> # Both the features and the labels tensors can be converted\n",
            "    >>> # to a Dataset object separately and combined after.\n",
            "    >>> features_dataset = Dataset.from_tensor_slices(features)\n",
            "    >>> labels_dataset = Dataset.from_tensor_slices(labels)\n",
            "    >>> dataset = Dataset.zip((features_dataset, labels_dataset))\n",
            "    >>> # A batched feature and label set can be converted to a Dataset\n",
            "    >>> # in similar fashion.\n",
            "    >>> batched_features = tf.constant([[[1, 3], [2, 3]],\n",
            "    ...                                 [[2, 1], [1, 2]],\n",
            "    ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
            "    >>> batched_labels = tf.constant([['A', 'A'],\n",
            "    ...                               ['B', 'B'],\n",
            "    ...                               ['A', 'B']], shape=(3, 2, 1))\n",
            "    >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
            "    >>> for element in dataset.as_numpy_iterator():\n",
            "    ...   print(element)\n",
            "    (array([[1, 3],\n",
            "           [2, 3]], dtype=int32), array([[b'A'],\n",
            "           [b'A']], dtype=object))\n",
            "    (array([[2, 1],\n",
            "           [1, 2]], dtype=int32), array([[b'B'],\n",
            "           [b'B']], dtype=object))\n",
            "    (array([[3, 3],\n",
            "           [3, 2]], dtype=int32), array([[b'A'],\n",
            "           [b'B']], dtype=object))\n",
            "    \n",
            "    Note that if `tensors` contains a NumPy array, and eager execution is not\n",
            "    enabled, the values will be embedded in the graph as one or more\n",
            "    `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
            "    memory and run into byte limits of graph serialization. If `tensors`\n",
            "    contains one or more large NumPy arrays, consider the alternative described\n",
            "    in [this guide](\n",
            "    https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
            "    \n",
            "    Args:\n",
            "      tensors: A dataset element, with each component having the same size in\n",
            "        the first dimension.\n",
            "    \n",
            "    Returns:\n",
            "      Dataset: A `Dataset`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm-VYqWMxKRf",
        "outputId": "357e0df9-5757-48fe-eb34-cc4d89171ca2"
      },
      "source": [
        "type(char_dataset)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi-J6jOixKpU"
      },
      "source": [
        "# for item in char_dataset.take(50):\r\n",
        "#   print(ind_to_char[item.numpy()])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b3U0glcBMoG",
        "outputId": "a6744b68-7b5a-489f-e8ba-5fa7eee4b022"
      },
      "source": [
        "help(char_dataset.batch)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method batch in module tensorflow.python.data.ops.dataset_ops:\n",
            "\n",
            "batch(batch_size, drop_remainder=False) method of tensorflow.python.data.ops.dataset_ops.TensorSliceDataset instance\n",
            "    Combines consecutive elements of this dataset into batches.\n",
            "    \n",
            "    >>> dataset = tf.data.Dataset.range(8)\n",
            "    >>> dataset = dataset.batch(3)\n",
            "    >>> list(dataset.as_numpy_iterator())\n",
            "    [array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]\n",
            "    \n",
            "    >>> dataset = tf.data.Dataset.range(8)\n",
            "    >>> dataset = dataset.batch(3, drop_remainder=True)\n",
            "    >>> list(dataset.as_numpy_iterator())\n",
            "    [array([0, 1, 2]), array([3, 4, 5])]\n",
            "    \n",
            "    The components of the resulting element will have an additional outer\n",
            "    dimension, which will be `batch_size` (or `N % batch_size` for the last\n",
            "    element if `batch_size` does not divide the number of input elements `N`\n",
            "    evenly and `drop_remainder` is `False`). If your program depends on the\n",
            "    batches having the same outer dimension, you should set the `drop_remainder`\n",
            "    argument to `True` to prevent the smaller batch from being produced.\n",
            "    \n",
            "    Args:\n",
            "      batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
            "        consecutive elements of this dataset to combine in a single batch.\n",
            "      drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
            "        whether the last batch should be dropped in the case it has fewer than\n",
            "        `batch_size` elements; the default behavior is not to drop the smaller\n",
            "        batch.\n",
            "    \n",
            "    Returns:\n",
            "      Dataset: A `Dataset`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlA8Z398xKs9"
      },
      "source": [
        "#batch_size : no. of elements in a single batch\r\n",
        "#drop reaminder: leaves the remaining part \r\n",
        "#output would be total_num_sequences of each with length 121\r\n",
        "\r\n",
        "sequences = char_dataset.batch(batch_size= seq_len +1, drop_remainder= True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckp9V5jrx_Y1",
        "outputId": "2e13612d-6a26-48c0-d53f-a05fec523203"
      },
      "source": [
        "for x in sequences.take(1):\r\n",
        "  print(\"Sequence as a tensor\")\r\n",
        "  print(x)\r\n",
        "  print(\"\\n\")\r\n",
        "  print(\"Sequence as a numpy array\")\r\n",
        "  print(x.numpy())\r\n",
        "  print(x.numpy().shape)\r\n",
        "### As can be seen now we have built ourselves sequneces of size (seq_len+1) each and here are the first two such sequences"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence as a tensor\n",
            "tf.Tensor(\n",
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75\n",
            "  1], shape=(121,), dtype=int64)\n",
            "\n",
            "\n",
            "Sequence as a numpy array\n",
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75\n",
            "  1]\n",
            "(121,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwvJBo-lBnl5",
        "outputId": "f4edc9bb-8d4c-49e8-da00-aee1edab1d5d"
      },
      "source": [
        "#visualizing the sequences\r\n",
        "\r\n",
        "for x in sequences.take(2):\r\n",
        "\r\n",
        "  print(\"Sequence as a numpy array\")\r\n",
        "  print(\"\".join(ind_to_char[x.numpy()]))\r\n",
        "  print(x.numpy().shape)\r\n",
        "### As can be seen now we have built ourselves sequneces of size (seq_len+1) each and here are the first two such sequences"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence as a numpy array\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n",
            "(121,)\n",
            "Sequence as a numpy array\n",
            "as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright e\n",
            "(121,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z9l_Zfkx_bF"
      },
      "source": [
        "#Now we need to create a sequence of outputs i.e. a sequence shifted by one character\r\n",
        "\r\n",
        "def create_seq_targets(seq):\r\n",
        "  input_txt = seq[:-1]  #hello my name is adity\r\n",
        "  output_txt = seq[1:]    #hello my name is aditya\r\n",
        "  \r\n",
        "  return input_txt, output_txt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAyk6SXHx_dJ"
      },
      "source": [
        "dataset = sequences.map(create_seq_targets)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JLHTaiSx_fK",
        "outputId": "7058244a-81de-4a5a-cb15-42ff878ce648"
      },
      "source": [
        "for input,output in dataset.take(1):   #Now have a [Input, Output] pair seqeunce\r\n",
        "  print(\"Sequence input\")\r\n",
        "  print(input)\r\n",
        "  print(\"\".join(ind_to_char[input.numpy()]))\r\n",
        "  print(input.shape)\r\n",
        "  print(\"\\n\")\r\n",
        "  print(\"Sequence output\")\r\n",
        "  print(output)\r\n",
        "  print(\"\".join(ind_to_char[output.numpy()]))\r\n",
        "  print(output.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence input\n",
            "tf.Tensor(\n",
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75], shape=(120,), dtype=int64)\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "(120,)\n",
            "\n",
            "\n",
            "Sequence output\n",
            "tf.Tensor(\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1], shape=(120,), dtype=int64)\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n",
            "(120,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDRdIT6t1YJy",
        "outputId": "eaf8ba60-5cc2-43b6-e923-a7e3f5cebd54"
      },
      "source": [
        "for input_seq, output_seq in dataset.take(2):\r\n",
        "  print(\"----- Input Sequence -----\")\r\n",
        "  print(input_seq.numpy())\r\n",
        "  print(\"\".join(ind_to_char[input_seq.numpy()]))\r\n",
        "\r\n",
        "  print(\"----- Output Sequence -----\")\r\n",
        "  print(output_seq.numpy())\r\n",
        "  print(\"\".join(ind_to_char[output_seq.numpy()]))\r\n",
        "  print(\"\\n\")\r\n",
        "\r\n",
        "#Notice the diffference in <START> , and <END> character in both case"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Input Sequence -----\n",
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "----- Output Sequence -----\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n",
            "\n",
            "\n",
            "----- Input Sequence -----\n",
            "[56 74  1 75 63 60  1 73 64 71 60 73  1 74 63 70 76 67 59  1 57 80  1 75\n",
            " 64 68 60  1 59 60 58 60 56 74 60  8  0  1  1 33 64 74  1 75 60 69 59 60\n",
            " 73  1 63 60 64 73  1 68 64 62 63 75  1 57 60 56 73  1 63 64 74  1 68 60\n",
            " 68 70 73 80 21  0  1  1 27 76 75  1 75 63 70 76  1 58 70 69 75 73 56 58\n",
            " 75 60 59  1 75 70  1 75 63 64 69 60  1 70 78 69  1 57 73 64 62 63 75  1]\n",
            "as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright \n",
            "----- Output Sequence -----\n",
            "[74  1 75 63 60  1 73 64 71 60 73  1 74 63 70 76 67 59  1 57 80  1 75 64\n",
            " 68 60  1 59 60 58 60 56 74 60  8  0  1  1 33 64 74  1 75 60 69 59 60 73\n",
            "  1 63 60 64 73  1 68 64 62 63 75  1 57 60 56 73  1 63 64 74  1 68 60 68\n",
            " 70 73 80 21  0  1  1 27 76 75  1 75 63 70 76  1 58 70 69 75 73 56 58 75\n",
            " 60 59  1 75 70  1 75 63 64 69 60  1 70 78 69  1 57 73 64 62 63 75  1 60]\n",
            "s the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright e\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn0uUof11YLo"
      },
      "source": [
        "batch_size = 128     #To train model in batches, we will feed batch_size(128) every time with sequence length 120 "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ttgpDY31YNw"
      },
      "source": [
        "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\r\n",
        "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\r\n",
        "\r\n",
        "\r\n",
        "buffer_size = 10000   #taking 10000 of batches and only shuffle them at one time\r\n",
        "\r\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder = True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-25oWIx71YPa",
        "outputId": "942a9d39-fca2-4e97-f3d2-5bd344bb546f"
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEcaTJ1WO8fM",
        "outputId": "65bc0938-6c24-41e7-be84-79b55edbf0a7"
      },
      "source": [
        "for input_batch, output_batch in dataset.take(1):\r\n",
        "  print(input_batch.shape)\r\n",
        "  print(\"\\n\")\r\n",
        "  print(output_batch.shape)\r\n",
        "  print(\"\".join(ind_to_char[input_batch[0,:].numpy()]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 120)\n",
            "\n",
            "\n",
            "(128, 120)\n",
            "ge th' ingratitude that despiteful Rome\n",
            "    Cast on my noble father.\n",
            "  CAESAR. Take your time.\n",
            "  ANTONY. Thou canst not \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKFD-Mfr1YRm",
        "outputId": "a97a27db-47c0-407b-ec8e-70aaf89ee48e"
      },
      "source": [
        "for inp_x, out_x in dataset.take(1):\r\n",
        "  print(inp_x.numpy())\r\n",
        "  print(\"\".join(ind_to_char[inp_x.numpy().reshape(15360,)]))    #note now that dataset has batch size 15360(128*120)\r\n",
        "\r\n",
        "  print(\"\\n\")\r\n",
        "  print(out_x.numpy())\r\n",
        "  #print(\"\".join(ind_to_char[inp_x.numpy()]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1 34  1 ... 60 56 74]\n",
            " [74  8  1 ...  1 50 70]\n",
            " [ 0  1  1 ... 67 60 75]\n",
            " ...\n",
            " [74  1 56 ...  0  1  1]\n",
            " [ 1 75 63 ...  1 61 70]\n",
            " [78 60 73 ... 75 10  0]]\n",
            " I am in this forest, and in man's\n",
            "    apparel? Looks he as freshly as he did the day he wrestled?\n",
            "  CELIA. It is as eass, which he knows is not to be done; damns himself to do,\n",
            "    and dares better be damn'd than to do 't.\n",
            "  FIRST LORD. Yo\n",
            "    Treachery! Seek it out.\n",
            "                                                [Laertes falls.]\n",
            "  Laer. It is here, Hamletre 'tis, that we may take it thence\n",
            "    And bear it to the chapel.\n",
            "  Ham. Do not believe it.\n",
            "  Ros. Believe what?\n",
            "  Ham.ver dwell,\n",
            "  Whate'er thy thoughts, or thy heart's workings be,\n",
            "  Thy looks should nothing thence, but sweetness tell.\n",
            " since that thou canst talk of love so well,\n",
            "    Thy company, which erst was irksome to me,\n",
            "    I will endure; and I'll e foul disease,\n",
            "    To keep it from divulging, let it feed\n",
            "    Even on the pith of life. Where is he gone?\n",
            "  Queen. To dried by the doer's deed;\n",
            "    Where great additions swell's, and virtue none,\n",
            "    It is a dropsied honour. Good alone\n",
            "    ose quality, going on,\n",
            "    The sides o' th' world may danger. Much is breeding\n",
            "    Which, like the courser's hair, hath rowner hath sate on her, and finds it Christian burial.\n",
            "  Clown. How can that be, unless she drown'd herself in her own\n",
            "l!\n",
            "\n",
            "    And of all Christian souls, I pray God. God b' wi', you.\n",
            "Exit.\n",
            "  Laer. Do you see this, O God?\n",
            "  King. Laertes, ? When spake I such a word?\n",
            "ANTIPHOLUS OF SYRACUSE. Even now, even here, not half an hour since.\n",
            "DROMIO OF SYRACUSE. I dentous figure\n",
            "    Comes armed through our watch, so like the King\n",
            "    That was and is the question of these wars.\n",
            "  Hor.ANA. O, know he is the bridle of your will.\n",
            "ADRIANA. There's none but asses will be bridled so.\n",
            "LUCIANA. Why, headstrongROLLES. 'Poor rogues' I pray you say.\n",
            "  FIRST SOLDIER. Well, that's set down.\n",
            "  PAROLLES. I humbly thank you, sir. A trur I may be pitied.\n",
            "  WIDOW. I am her mother, sir, whose age and honour\n",
            "    Both suffer under this complaint we bring,\n",
            "  HARMIAN. Behold, sir.                                    Exit\n",
            "  CLEOPATRA. Dolabella!  \n",
            "  DOLABELLA. Madam, as thereto sthat nimble leap,\n",
            "  To kiss the tender inward of thy hand,\n",
            "  Whilst my poor lips which should that harvest reap,\n",
            "  At th me:\n",
            "    My birthplace hate I, and my love's upon\n",
            "    This enemy town. I'll enter. If he slay me,\n",
            "    He does fair justiin apprehension how like a god! the\n",
            "    beauty of the world, the paragon of animals! And yet to me what\n",
            "    is this quintall,\n",
            "    That I did suit me all points like a man?\n",
            "    A gallant curtle-axe upon my thigh,\n",
            "    A boar spear in my hand;t shame to tell you what it means.\n",
            "  Oph. You are naught, you are naught! I'll mark the play.\n",
            "\n",
            "    Pro. For us, and for   Ham. The body is with the King, but the King is not with the body.\n",
            "    The King is a thing-\n",
            "  Guil. A thing, my lord?\n",
            " were better my mother had not borne me.  \n",
            "    I am very proud, revengeful, ambitious; with more offences at my\n",
            "    beckThe mobled queen'?\n",
            "  Pol. That's good! 'Mobled queen' is good.\n",
            "\n",
            "  1. Play. 'Run barefoot up and down, threat'ning the fl.\n",
            "  Hor. The same, my lord, and your poor servant ever.\n",
            "  Ham. Sir, my good friend- I'll change that name with you.\n",
            "    ts at full,\n",
            "    By letters congruing to that effect,\n",
            "    The present death of Hamlet. Do it, England;  \n",
            "    For like thel\n",
            "    scarcely lie in this box; and must th' inheritor himself have no\n",
            "    more, ha?\n",
            "  Hor. Not a jot more, my lord.\n",
            "  Hox I gave you was not thought by me\n",
            "    A precious thing! I had it from the Queen.\n",
            "  CYMBELINE. New matter still?\n",
            "  IMOG In all your business and necessities.\n",
            "  ORLANDO. O good old man, how well in thee appears  \n",
            "    The constant service ofGive me thy hand,\n",
            "    Thou has been rightly honest. So hast thou;\n",
            "    Thou, and thou, and thou. You have serv'd me well,ps me in a most humorous  \n",
            "    sadness.\n",
            "  ROSALIND. A traveller! By my faith, you have great reason to be\n",
            "    sad. I feapes and monkeys,\n",
            "    'Twixt two such shes, would chatter this way and\n",
            "    Contemn with mows the other; nor i' th' judgmeou follow her,\n",
            "    Like foggy south, puffing with wind and rain?\n",
            "    You are a thousand times a properer man  \n",
            "    Than  him?\n",
            "  OLIVER. 'Twas I; but 'tis not I. I do not shame\n",
            "    To tell you what I was, since my conversion\n",
            "    So sweetly tbe troubled with you; you shall have\n",
            "    some part of your will. I pray you leave me.\n",
            "  ORLANDO. I no further offend you    And I beseech you instantly to visit\n",
            "    My too much changed son.- Go, some of you,\n",
            "    And bring these gentlemen wh take\n",
            "    my leave of you.\n",
            "  Ham. You cannot, sir, take from me anything that I will more\n",
            "    willingly part withal- exche law's delay,\n",
            "    The insolence of office, and the spurns\n",
            "    That patient merit of th' unworthy takes,\n",
            "    When he hit flesh or fish,\n",
            "  A table full of welcome makes scarce one dainty dish.\n",
            "BALTHAZAR. Good meat, sir, is common; that ever in the balance that I could neither believe nor\n",
            "    misdoubt. Pray you leave me. Stall this in your bosom; and I\n",
            "    thit not, Hamlet denies it.\n",
            "    Who does it, then? His madness. If't be so,\n",
            "    Hamlet is of the faction that is wrong'd;\n",
            "e yet?\n",
            "  ANTONY. Alack, our terrene moon\n",
            "    Is now eclips'd, and it portends alone\n",
            "    The fall of Antony.\n",
            "  CLEOPATRA.ll as low an ebb as the\n",
            "    foot of the ladder, and by-and-by in as high a flow as the ridge\n",
            "    of the gallows.\n",
            "  Fal.  Of him, my self, and thee I am forsaken,\n",
            "  A torment thrice three-fold thus to be crossed:\n",
            "  Prison my heart in thy ste kind,  \n",
            "                So be sure will Rosalinde.\n",
            "                Winter garments must be lin'd,\n",
            "                So muht, whose love to you\n",
            "  (Though words come hindmost) holds his rank before,\n",
            "    Then others, for the breath of words resr annals true, 'tis there\n",
            "    That, like an eagle in a dove-cote, I\n",
            "    Flutter'd your Volscians in Corioli.\n",
            "    Alone Ier following me,\n",
            "  And soon and safe arrived where I was.\n",
            "  There had she not been long but she became\n",
            "  A joyful mothersolemn and so rare,\n",
            "  Since seldom coming in that long year set,\n",
            "  Like stones of worth they thinly placed are,\n",
            "  Or capnd 'mother'\n",
            "    So strive upon your pulse. What! pale again?  \n",
            "    My fear hath catch'd your fondness. Now I see\n",
            "    TheMad slanderers by mad ears believed be.\n",
            "    That I may not be so, nor thou belied,\n",
            "    Bear thine eyes straight, though re like\n",
            "    A halter'd neck which does the hangman thank\n",
            "    For being yare about him.\n",
            "\n",
            "              Re-enter a SERVANTs.\n",
            "  SECOND GENTLEMAN. That a king's children should be so convey'd,\n",
            "    So slackly guarded, and the search so slow\n",
            "    p it on. And, sweetest, fairest,\n",
            "    As I my poor self did exchange for you,\n",
            "    To your so infinite loss, so in our triet this\n",
            "    foolish Imogen, I should have gold enough. It's almost morning,\n",
            "    is't not?\n",
            "  FIRST LORD. Day, my lord.\n",
            "  souls) give thee that due,\n",
            "  Uttering bare truth, even so as foes commend.\n",
            "  Thy outward thus with outward praise is croou speak with me. You shall at least\n",
            "    Go see my lord aboard. For this time leave me.        Exeunt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCENE II.\n",
            "Britam satisfied in nature,\n",
            "    Whose motive in this case should stir me most\n",
            "    To my revenge. But in my terms of honour\n",
            " hter to the Widow\n",
            "\n",
            "\n",
            "  VIOLENTA, neighbour and friend to the Widow\n",
            "  MARIANA, neighbour and friend to the Widow\n",
            "\n",
            "  Lords,ove's might:  \n",
            "  O let my looks be then the eloquence,\n",
            "  And dumb presagers of my speaking breast,\n",
            "  Who plead for love,s and greetings;\n",
            "    Say that I wish he never find more cause\n",
            "    To change a master. O, my fortunes have\n",
            "    Corrupted US. Away! The tribunes do attend you. Arm yourself\n",
            "    To answer mildly; for they are prepar'd\n",
            "    With accusations, as  I'll be no more;\n",
            "    But I will eat, and drink, and sleep as soft\n",
            "    As captain shall. Simply the thing I am\n",
            "    Shall. Dear Celia, I show more mirth than I am mistress of; and\n",
            "    would you yet I were merrier? Unless you could teach me tt, nor I no wife.\n",
            "  Give me thy hand.\n",
            "LUCIANA. O, soft, sir, hold you still;\n",
            "  I'll fetch my sister to get her good willn.\n",
            "  SECOND SERVANT. Why, this it is to have a name in great men's\n",
            "    fellowship. I had as lief have a reed that will dm. Ingratitude is\n",
            "    monstrous, and for the multitude to be ingrateful were to make a\n",
            "    monster of the multitude; of n into this danger.\n",
            "    Yet who would have suspected an ambush where I was taken?\n",
            "  FIRST SOLDIER. There is no remedy, s There she appear'd indeed! Or my reporter devis'd well for\n",
            "    her.\n",
            "  ENOBARBUS. I will tell you.\n",
            "    The barge she satce I saw him,\n",
            "    But time hath nothing blurr'd those lines of favour\n",
            "    Which then he wore; the snatches in his voice,rriage-day.\n",
            "  COUNTESS. Which better than the first, O dear heaven, bless!\n",
            "    Or, ere they meet, in me, O nature, cesse man\n",
            "    in good earnest, nor no further in sport neither than with safety\n",
            "    of a pure blush thou mayst in honour come's volume\n",
            "    Our Britain seems as of it, but not in't;\n",
            "    In a great pool a swan's nest. Prithee think\n",
            "    There's liv pile and a half, but his right cheek is worn bare.\n",
            "  LAFEU. A scar nobly got, or a noble scar, is a good liv'ry of\n",
            "    d. Why, he's able to lead her a\n",
            "    coranto.\n",
            "  PAROLLES. Mort du vinaigre! Is not this Helen?\n",
            "  LAFEU. 'Fore God, I thint much skill in\n",
            "    grass.  \n",
            "  LAFEU. Whether dost thou profess thyself-a knave or a fool?\n",
            "  CLOWN. A fool, sir, at a woter.\n",
            "    So holy writ in babes hath judgment shown,\n",
            "    When judges have been babes. Great floods have flown\n",
            "    From siave' without a knock.\n",
            "  CLOTEN. Thou art a robber,\n",
            "    A law-breaker, a villain. Yield thee, thief.\n",
            "  GUIDERIUS. To who?ules\n",
            "    Did shake down mellow fruit. You have made fair work!\n",
            "  BRUTUS. But is this true, sir?\n",
            "  COMINIUS. Ay; and you'u in me can nothing worthy prove.  \n",
            "  Unless you would devise some virtuous lie,\n",
            "  To do more for me than mine own desergether, but to come by him where he\n",
            "    stands, by ones, by twos, and by threes. He's to make his\n",
            "    requests by particct the creeping hours of time;\n",
            "    If ever you have look'd on better days,\n",
            "    If ever been where bells have knoll'd to  and thus; averring notes\n",
            "    Of chamber-hanging, pictures, this her bracelet-\n",
            "    O cunning, how I got it!- nay, some mstands on tricks when I am undispos'd.\n",
            "  Where is the thousand marks thou hadst of me?\n",
            "DROMIO OF EPHESUS. I have some maple sources, and great seas have dried\n",
            "    When miracles have by the greatest been denied.\n",
            "    Oft expectation fails, an, come hither, come hither.\n",
            "               Here shall he see\n",
            "               No enemy\n",
            "             But winter and rough wscharg'd this honestly; keep it to yourself.\n",
            "    Many likelihoods inform'd me of this before, which hung so\n",
            "    tott'rinth a perpetual dulness:\n",
            "  Let this sad interim like the ocean be\n",
            "  Which parts the shore, where two contracted new,\n",
            "  Co shall fare\n",
            "    the better for you; and there's an end.\n",
            "  LUCIUS. So, sir.\n",
            "  CYMBELINE. I know your master's pleasure, a brothers, and to knit your hearts\n",
            "    With an unslipping knot, take Antony\n",
            "    Octavia to his wife; whose beauty claims         96  \n",
            "  Some say thy fault is youth, some wantonness,\n",
            "  Some say thy grace is youth and gentle sport,\n",
            "  Both grayour daughter, ere she seems as won,\n",
            "    Desires this ring; appoints him an encounter;\n",
            "    In fine, delivers me to fill    Vanquish my staider senses. What's the matter?\n",
            "    Why tender'st thou that paper to me with\n",
            "    A look untender! If't  And not have strew'd thy grave.\n",
            "  Laer. O, treble woe\n",
            "    Fall ten times treble on that cursed head\n",
            "    Whose wicked do;\n",
            "    The which shall turn you to no further harm\n",
            "    Than so much loss of time.\n",
            "  SICINIUS. Speak briefly, then,\n",
            "    F My mother did but duty; such, my lord,\n",
            "    As you owe to your wife.\n",
            "  BERTRAM. No more o'that!  \n",
            "    I prithee do not sILLINOIS BENEDICTINE COLLEGE\n",
            "WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\n",
            "DISTRIBUTED SO LONG AS SUCHere now but to begin,\n",
            "    Antiquity forgot, custom not known,\n",
            "    The ratifiers and props of every word,\n",
            "    They cry 'Ce and faults are loved of more and less:\n",
            "  Thou mak'st faults graces, that to thee resort:\n",
            "  As on the finger of a thron word how tall she is.- Pity me, Charmian,\n",
            "    But do not speak to me. Lead me to my chamber.        Exeunt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SCENE VIrcely hears\n",
            "    Of this his nephew's purpose, to suppress\n",
            "    His further gait herein, in that the levies,\n",
            "    The lists   his design; let him fetch off his drum in any hand.\n",
            "  BERTRAM. How now, monsieur! This drum sticks sorely in your  \n",
            " t's that?\n",
            "DROMIO OF SYRACUSE. Basting.\n",
            "ANTIPHOLUS OF SYRACUSE. Well, sir, then 'twill be dry.\n",
            "DROMIO OF SYRACUSE. If it n him so\n",
            "    pictur'd. You must either be directed by some that take upon them\n",
            "    to know, or to take upon yourself tha DUKE SENIOR. Come, shall we go and kill us venison?\n",
            "    And yet it irks me the poor dappled fools,\n",
            "    Being native bury conscience, thou art fetter'd\n",
            "    More than my shanks and wrists; you good gods, give me\n",
            "    The penitent instrument tmust be my brother?\n",
            "  COUNTESS. Yes, Helen, you might be my daughter-in-law.\n",
            "    God shield you mean it not! 'daughter' he infants of the spring\n",
            "    Too oft before their buttons be disclos'd,\n",
            "    And in the morn and liquid dew of youth\n",
            "    injuries, to be friends;\n",
            "    Pays dear for my offences.                              Exit\n",
            "  POSTHUMUS. Should we be taki delight,\n",
            "  To see his active child do deeds of youth,\n",
            "  So I, made lame by Fortune's dearest spite\n",
            "  Take all my comforLORD. Stand you? You have land enough of your own; but he\n",
            "    added to your having, gave you some ground.\n",
            "  SECOND LORD.ngth, and defence,\n",
            "    That Rome can make against them.  \n",
            "\n",
            "                       Enter a troop of citizens\n",
            "\n",
            "  MENENIUS.harmian!\n",
            "  CHARMIAN. Madam?\n",
            "  CLEOPATRA. Ha, ha!\n",
            "    Give me to drink mandragora.\n",
            "  CHARMIAN. Why, madam?\n",
            "  CLEOPATRA. TAnd wager on your heads. He, being remiss,\n",
            "    Most generous, and free from all contriving,\n",
            "    Will not peruse the foilapons!\n",
            "                              [They all bustle about CORIOLANUS]\n",
            "  ALL. Tribunes! patricians! citizens! What, ho!  And nothing pleaseth but rare accidents.\n",
            "    So, when this loose behaviour I throw off  \n",
            "    And pay the debt I never rook; look but in, and you shall see\n",
            "    him.\n",
            "  JAQUES. There I shall see mine own figure.\n",
            "  ORLANDO. Which I take to ber,\n",
            "    For truth proves thievish for a prize so dear.\n",
            "\n",
            "\n",
            "                     49\n",
            "  Against that time (if ever that time c\n",
            "    Would stand and make his eyes grow in my brow;  \n",
            "    There would he anchor his aspect and die\n",
            "    With looking on he of many parts\n",
            "             By heavenly synod was devis'd,\n",
            "           Of many faces, eyes, and hearts,\n",
            "             To eavens mend! Alexas- come, his\n",
            "    fortune, his fortune! O, let him marry a woman that cannot go,\n",
            "    sweet Isis, I beselars, wherein every one of us has a single\n",
            "    honour, in giving him our own voices with our own tongues;\n",
            "    therefore \n",
            "  Even as when first I hallowed thy fair name.\n",
            "  So that eternal love in love's fresh case,\n",
            "  Weighs not the dust and iremembrance fitted.\n",
            "  Oph. There's fennel for you, and columbines. There's rue for you,\n",
            "    and here's some for me. We ms all,\n",
            "    With measure heap'd in joy, to th' measures fall.\n",
            "  JAQUES. Sir, by your patience. If I heard you rightly,\n",
            "   that did see her.\n",
            "    The ladies, her attendants of her chamber,\n",
            "    Saw her abed, and in the morning early\n",
            "    They fowere they chosen; in a better hour\n",
            "    Let what is meet be said it must be meet,\n",
            "    And throw their power i' th' dust.\n",
            "\n",
            "\n",
            "\n",
            "[[34  1 56 ... 56 74 80]\n",
            " [ 8  1 78 ... 50 70 76]\n",
            " [ 1  1  1 ... 60 75 10]\n",
            " ...\n",
            " [ 1 56 67 ...  1  1  1]\n",
            " [75 63 56 ... 61 70 76]\n",
            " [60 73 60 ... 10  0  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcbTA78d1bOJ",
        "outputId": "ea50110a-7acf-428e-b332-4fb468cf3942"
      },
      "source": [
        "dataset\r\n",
        "# <BatchDataset shapes: ((128, 120), (128, 120))\r\n",
        "# First tuple: (batch_size , input_size)\r\n",
        "# Second tuple: (batch_size , output_size)\r\n",
        "\r\n",
        "#At each batch, we will be feeding 128 sequences at a time, and each of these sequence are of length 120"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pj68wUO6PvT"
      },
      "source": [
        "### Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D30gO6fxKwr",
        "outputId": "2c33832c-d6c6-4625-aafb-38f5792bc48c"
      },
      "source": [
        "embed_dim = 64  #Chosen basis your vocab size, In our case its 84(eighty four)\r\n",
        "rnn_neurons = 1026 #Chosen only one RNN layer\r\n",
        "vocab_size = len(vocab)    #vocab size\r\n",
        "print(vocab_size)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1NbKkqsxKys",
        "outputId": "058bf10e-dceb-4f8a-daa0-d2522970a670"
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\r\n",
        "help(sparse_categorical_crossentropy)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function sparse_categorical_crossentropy in module tensorflow.python.keras.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Standalone usage:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss.numpy()\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "    \n",
            "    Args:\n",
            "      y_true: Ground truth values.\n",
            "      y_pred: The predicted values.\n",
            "      from_logits: Whether `y_pred` is expected to be a logits tensor. By default,\n",
            "        we assume that `y_pred` encodes a probability distribution.\n",
            "      axis: (Optional) Defaults to -1. The dimension along which the entropy is\n",
            "        computed.\n",
            "    \n",
            "    Returns:\n",
            "      Sparse categorical crossentropy loss value.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyZZyGFdARIQ"
      },
      "source": [
        "def sparse_cat_loss(y_true, y_pred):\r\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHFgLgEzAoDE"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\r\n",
        "\r\n",
        "#vocab_size : Needed fro Embedding layer to generate the embeddings\r\n",
        "\r\n",
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(vocab_size, embed_dim, batch_input_shape = [batch_size, None]))\r\n",
        "  model.add(GRU(rnn_neurons, return_sequences = True, stateful = True, recurrent_initializer = \"glorot_uniform\"))\r\n",
        "  model.add(Dense(vocab_size))\r\n",
        "\r\n",
        "  model.compile(optimizer = \"adam\", loss = sparse_cat_loss)\r\n",
        "\r\n",
        "  return model\r\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vciu072NAoFP"
      },
      "source": [
        "model = create_model(vocab_size = vocab_size, \r\n",
        "                     embed_dim = embed_dim, \r\n",
        "                     rnn_neurons = rnn_neurons, \r\n",
        "                     batch_size=batch_size)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXJATj_NAoHL",
        "outputId": "b1c03aaf-7a16-4ede-da5f-d2cc69f90415"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 64)           5376      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (128, None, 1026)         3361176   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 84)           86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFFG9CspDJNo"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQFhLUcXFxus"
      },
      "source": [
        "##### Prior training observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0VxTgrHAoI-"
      },
      "source": [
        "for input_example_batch, output_example_batch in dataset.take(1):\r\n",
        "\r\n",
        "  example_bacth_predictions = model(input_example_batch)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjWSDh38nu20",
        "outputId": "d7df196c-a8aa-4c7a-ec00-7f7d17a4d1dd"
      },
      "source": [
        "example_bacth_predictions.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 120, 84])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNERKL1LF7Sy"
      },
      "source": [
        "'''\r\n",
        "So basically it generated 128 random sequences for me each having size 120*84. 84 is vector_embeeding size\r\n",
        "for each unique character in our vocab. That is to say it each 120 output predicted will have a PMF vector \r\n",
        "of size 84 units\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O32WIdXHF7VT",
        "outputId": "841de078-179c-4879-b314-7f4619b08471"
      },
      "source": [
        "example_bacth_predictions[0]\r\n",
        "print(ind_to_char[np.argmax(example_bacth_predictions[0][77].numpy())])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "U\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT_mRtu6GTuH"
      },
      "source": [
        "\"Assume it as a 3D matrix, with 128 as no of layers and 120*84 as dimention of each layer\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lec1gTqSF7Z3"
      },
      "source": [
        "# sampled_indices = tf.random.categorical(example_bacth_predictions[0], num_samples = 1)\r\n",
        "# print(sampled_indices)\r\n",
        "\r\n",
        "sampled_indices2 = tf.random.categorical(example_bacth_predictions[0], num_samples=1).numpy()\r\n",
        "print(sampled_indices2[-1,0])\r\n",
        "print(sampled_indices2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "kUQm6-AqAoMC",
        "outputId": "fe86d987-10d3-4b35-9df4-1b6031c08cfc"
      },
      "source": [
        "\"\".join(ind_to_char[np.squeeze(sampled_indices.numpy())])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'KcW|YlLj.:wgrp0KR|,iS>ZNAiw[Y<R!l WaFomDCa-_5z)}8rV]L3lt4i7[Jvd7IsK`\\n9j_9 FJ?g5)zpRB]DdZmA| Rp,iYVWBY|7mb.RW202yWGs,s:Av'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aICjzlbYAoOL"
      },
      "source": [
        "#some random gibbersish"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMbGY5tSHncc"
      },
      "source": [
        "##### Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKG-hWecAoRo",
        "outputId": "5bc2e16e-a0e3-429a-8a9c-b79b1faab5e1"
      },
      "source": [
        "epochs = 15\r\n",
        "\r\n",
        "model_history = model.fit(dataset, epochs = epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "351/351 [==============================] - 50s 137ms/step - loss: 3.1766\n",
            "Epoch 2/15\n",
            "351/351 [==============================] - 47s 131ms/step - loss: 1.8632\n",
            "Epoch 3/15\n",
            "351/351 [==============================] - 48s 135ms/step - loss: 1.5295\n",
            "Epoch 4/15\n",
            "351/351 [==============================] - 48s 132ms/step - loss: 1.3800\n",
            "Epoch 5/15\n",
            "351/351 [==============================] - 47s 131ms/step - loss: 1.3042\n",
            "Epoch 6/15\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 1.2574\n",
            "Epoch 7/15\n",
            "351/351 [==============================] - 48s 134ms/step - loss: 1.2255\n",
            "Epoch 8/15\n",
            "351/351 [==============================] - 49s 136ms/step - loss: 1.1991\n",
            "Epoch 9/15\n",
            "351/351 [==============================] - 48s 134ms/step - loss: 1.1789\n",
            "Epoch 10/15\n",
            "351/351 [==============================] - 48s 134ms/step - loss: 1.1604\n",
            "Epoch 11/15\n",
            "351/351 [==============================] - 48s 134ms/step - loss: 1.1437\n",
            "Epoch 12/15\n",
            "351/351 [==============================] - 47s 131ms/step - loss: 1.1287\n",
            "Epoch 13/15\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 1.1158\n",
            "Epoch 14/15\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 1.1023\n",
            "Epoch 15/15\n",
            "351/351 [==============================] - 48s 133ms/step - loss: 1.0897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3I7sQLiIo9F"
      },
      "source": [
        "model.save(\"text_generation.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "SMXU51NH0WEn",
        "outputId": "aadf88b9-09e7-4ed0-f6cd-bb99dfddf680"
      },
      "source": [
        "model_df = pd.DataFrame(model_history.history)\r\n",
        "model_df.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8c3bdbef28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM5HecVAIdPn"
      },
      "source": [
        "### Create a model to have user_defind batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpgUVRS4AoT3"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size = 1)\r\n",
        "model.load_weights(\"/content/text_generation.h5\")\r\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGwrnqwvDn47",
        "outputId": "2b371d51-e075-4b18-d129-4a6edf9d82c1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 64)             5376      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 84)             86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5YuezIdKdDu"
      },
      "source": [
        "**The prediction loop**\r\n",
        "\r\n",
        "The following code block generates the text:\r\n",
        "Begin by choosing a start string, initializing the RNN state and setting the number of characters to generate.  \r\n",
        "\r\n",
        "Get the prediction distribution of the next character using the start string and the RNN state.  \r\n",
        "\r\n",
        "Then, use a categorical distribution to calculate the index of the predicted character. Use this predicted character as our next input to the model.  \r\n",
        "\r\n",
        "The RNN state returned by the model is fed back into the model so that it now has more context, instead of only one character. After predicting the next character, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted characters.  \r\n",
        "\r\n",
        "![text_generation_sampling.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jhF2A71Dn8w"
      },
      "source": [
        "def generate_text(model, start_seed, gen_size = 100, temp = 1.0):\r\n",
        "  '''\r\n",
        "  model: Trained Model to Generate Text\r\n",
        "  start_seed: Intial Seed text in string form\r\n",
        "  gen_size: Number of characters to generate\r\n",
        "\r\n",
        "  Basic idea behind this function is to take in some seed text, format it so\r\n",
        "  that it is in the correct shape for our network, then loop the sequence as\r\n",
        "  we keep adding our own predicted characters. Similar to our work in the RNN\r\n",
        "  time series problems.\r\n",
        "  '''\r\n",
        "\r\n",
        "  # Number of characters to generate\r\n",
        "  num_generate = gen_size\r\n",
        "\r\n",
        "  # Encoding starting seed text\r\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\r\n",
        "\r\n",
        "  # Expand to match batch format shape\r\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\r\n",
        "  # print(input_eval.shape)\r\n",
        "  # Empty list to hold resulting generated text\r\n",
        "  text_generated = []\r\n",
        "\r\n",
        "  # Temperature effects randomness in our resulting text\r\n",
        "  # The term is derived from entropy/thermodynamics.\r\n",
        "  # The temperature is used to effect probability of next characters.\r\n",
        "  # Higher probability == lesss surprising/ more expected\r\n",
        "  # Lower temperature == more surprising / less expected\r\n",
        "\r\n",
        "  temperature = temp\r\n",
        "\r\n",
        "  #Batch_size == 1\r\n",
        "  model.reset_states()\r\n",
        "\r\n",
        "  for i in range(num_generate):\r\n",
        "\r\n",
        "    # Generate Predictions\r\n",
        "    predictions = model(input_eval)\r\n",
        "    #print(\"predictions_shape:\", predictions.shape)    #Initially Shape: (1,6,84), then (1,1,84)\r\n",
        "\r\n",
        "    # Remove the batch shape dimension\r\n",
        "    predictions = tf.squeeze(predictions, 0)           #Initially Shape: (6,84), then (1,84)\r\n",
        "    \r\n",
        "    \r\n",
        "    # Use a cateogircal disitribution to select the next character\r\n",
        "    predictions = predictions/temperature\r\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1,0].numpy()\r\n",
        "\r\n",
        "    print(predicted_id)\r\n",
        "    print(\"before input_eval\")\r\n",
        "    print(input_eval)\r\n",
        "    input_eval = tf.expand_dims([predicted_id], 0 )\r\n",
        "    print(\"After input eval\")\r\n",
        "    print(input_eval)\r\n",
        "\r\n",
        "    text_generated.append(ind_to_char[predicted_id])\r\n",
        "\r\n",
        "  return (start_seed + \"\".join(text_generated))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHKfm1mUDn-y",
        "outputId": "93fc6f51-fe4c-481d-c3c5-1a1549785910"
      },
      "source": [
        "print(generate_text(model, \"JULIET\", gen_size = 100))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n",
            "before input_eval\n",
            "tf.Tensor([[35 46 37 34 30 45]], shape=(1, 6), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[33]], shape=(1, 1), dtype=int32)\n",
            "10\n",
            "before input_eval\n",
            "tf.Tensor([[33]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "44\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[44]], shape=(1, 1), dtype=int32)\n",
            "63\n",
            "before input_eval\n",
            "tf.Tensor([[44]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[63]], shape=(1, 1), dtype=int32)\n",
            "60\n",
            "before input_eval\n",
            "tf.Tensor([[63]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "63\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[63]], shape=(1, 1), dtype=int32)\n",
            "60\n",
            "before input_eval\n",
            "tf.Tensor([[63]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "56\n",
            "before input_eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "73\n",
            "before input_eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[73]], shape=(1, 1), dtype=int32)\n",
            "74\n",
            "before input_eval\n",
            "tf.Tensor([[73]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[74]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[74]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "75\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[75]], shape=(1, 1), dtype=int32)\n",
            "63\n",
            "before input_eval\n",
            "tf.Tensor([[75]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[63]], shape=(1, 1), dtype=int32)\n",
            "60\n",
            "before input_eval\n",
            "tf.Tensor([[63]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "67\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[67]], shape=(1, 1), dtype=int32)\n",
            "56\n",
            "before input_eval\n",
            "tf.Tensor([[67]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "73\n",
            "before input_eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[73]], shape=(1, 1), dtype=int32)\n",
            "66\n",
            "before input_eval\n",
            "tf.Tensor([[73]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[66]], shape=(1, 1), dtype=int32)\n",
            "10\n",
            "before input_eval\n",
            "tf.Tensor([[66]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "0\n",
            "before input_eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[0]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[0]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "37\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[37]], shape=(1, 1), dtype=int32)\n",
            "40\n",
            "before input_eval\n",
            "tf.Tensor([[37]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[40]], shape=(1, 1), dtype=int32)\n",
            "43\n",
            "before input_eval\n",
            "tf.Tensor([[40]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[43]], shape=(1, 1), dtype=int32)\n",
            "30\n",
            "before input_eval\n",
            "tf.Tensor([[43]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[30]], shape=(1, 1), dtype=int32)\n",
            "39\n",
            "before input_eval\n",
            "tf.Tensor([[30]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[39]], shape=(1, 1), dtype=int32)\n",
            "51\n",
            "before input_eval\n",
            "tf.Tensor([[39]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[51]], shape=(1, 1), dtype=int32)\n",
            "40\n",
            "before input_eval\n",
            "tf.Tensor([[51]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[40]], shape=(1, 1), dtype=int32)\n",
            "10\n",
            "before input_eval\n",
            "tf.Tensor([[40]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "34\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[34]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[34]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "67\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[67]], shape=(1, 1), dtype=int32)\n",
            "60\n",
            "before input_eval\n",
            "tf.Tensor([[67]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "56\n",
            "before input_eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "77\n",
            "before input_eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[77]], shape=(1, 1), dtype=int32)\n",
            "60\n",
            "before input_eval\n",
            "tf.Tensor([[77]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "80\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[80]], shape=(1, 1), dtype=int32)\n",
            "70\n",
            "before input_eval\n",
            "tf.Tensor([[80]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[70]], shape=(1, 1), dtype=int32)\n",
            "76\n",
            "before input_eval\n",
            "tf.Tensor([[70]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[76]], shape=(1, 1), dtype=int32)\n",
            "10\n",
            "before input_eval\n",
            "tf.Tensor([[76]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "0\n",
            "before input_eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[0]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[0]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "29\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[29]], shape=(1, 1), dtype=int32)\n",
            "46\n",
            "before input_eval\n",
            "tf.Tensor([[29]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[46]], shape=(1, 1), dtype=int32)\n",
            "36\n",
            "before input_eval\n",
            "tf.Tensor([[46]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[36]], shape=(1, 1), dtype=int32)\n",
            "30\n",
            "before input_eval\n",
            "tf.Tensor([[36]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[30]], shape=(1, 1), dtype=int32)\n",
            "10\n",
            "before input_eval\n",
            "tf.Tensor([[30]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "43\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[43]], shape=(1, 1), dtype=int32)\n",
            "60\n",
            "before input_eval\n",
            "tf.Tensor([[43]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "64\n",
            "before input_eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[64]], shape=(1, 1), dtype=int32)\n",
            "62\n",
            "before input_eval\n",
            "tf.Tensor([[64]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[62]], shape=(1, 1), dtype=int32)\n",
            "69\n",
            "before input_eval\n",
            "tf.Tensor([[62]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[69]], shape=(1, 1), dtype=int32)\n",
            "8\n",
            "before input_eval\n",
            "tf.Tensor([[69]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[8]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[8]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "56\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "74\n",
            "before input_eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[74]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[74]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "80\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[80]], shape=(1, 1), dtype=int32)\n",
            "70\n",
            "before input_eval\n",
            "tf.Tensor([[80]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[70]], shape=(1, 1), dtype=int32)\n",
            "76\n",
            "before input_eval\n",
            "tf.Tensor([[70]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[76]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[76]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "58\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[58]], shape=(1, 1), dtype=int32)\n",
            "73\n",
            "before input_eval\n",
            "tf.Tensor([[58]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[73]], shape=(1, 1), dtype=int32)\n",
            "64\n",
            "before input_eval\n",
            "tf.Tensor([[73]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[64]], shape=(1, 1), dtype=int32)\n",
            "60\n",
            "before input_eval\n",
            "tf.Tensor([[64]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "59\n",
            "before input_eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[59]], shape=(1, 1), dtype=int32)\n",
            "8\n",
            "before input_eval\n",
            "tf.Tensor([[59]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[8]], shape=(1, 1), dtype=int32)\n",
            "0\n",
            "before input_eval\n",
            "tf.Tensor([[8]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[0]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[0]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "38\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[38]], shape=(1, 1), dtype=int32)\n",
            "80\n",
            "before input_eval\n",
            "tf.Tensor([[38]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[80]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[80]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "78\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[78]], shape=(1, 1), dtype=int32)\n",
            "70\n",
            "before input_eval\n",
            "tf.Tensor([[78]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[70]], shape=(1, 1), dtype=int32)\n",
            "68\n",
            "before input_eval\n",
            "tf.Tensor([[70]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[68]], shape=(1, 1), dtype=int32)\n",
            "57\n",
            "before input_eval\n",
            "tf.Tensor([[68]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[57]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[57]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "59\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[59]], shape=(1, 1), dtype=int32)\n",
            "60\n",
            "before input_eval\n",
            "tf.Tensor([[59]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "61\n",
            "before input_eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[61]], shape=(1, 1), dtype=int32)\n",
            "60\n",
            "before input_eval\n",
            "tf.Tensor([[61]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "56\n",
            "before input_eval\n",
            "tf.Tensor([[60]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "75\n",
            "before input_eval\n",
            "tf.Tensor([[56]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[75]], shape=(1, 1), dtype=int32)\n",
            "8\n",
            "before input_eval\n",
            "tf.Tensor([[75]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[8]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[8]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "57\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[57]], shape=(1, 1), dtype=int32)\n",
            "80\n",
            "before input_eval\n",
            "tf.Tensor([[57]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[80]], shape=(1, 1), dtype=int32)\n",
            "1\n",
            "before input_eval\n",
            "tf.Tensor([[80]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "75\n",
            "before input_eval\n",
            "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
            "After input eval\n",
            "tf.Tensor([[75]], shape=(1, 1), dtype=int32)\n",
            "JULIETH. She hears the lark.\n",
            "  LORENZO. I leave you.\n",
            "  DUKE. Reign, as you cried,\n",
            "    My womb defeat, by t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbCeI4GbDoAz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}